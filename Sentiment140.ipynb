{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment140.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSyGD_lWNrO1",
        "colab_type": "code",
        "outputId": "695dfaed-9ca5-47b3-e314-17f6bdbd2304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "\n",
        "def GoogleDriveAuth(ID):\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    file = drive.CreateFile({'id': ID})\n",
        "    return file\n",
        "\n",
        "File_ID = '1XYOhPmDIQNexg-XgOgP29qc1KxVleXwt'\n",
        "file_name = GoogleDriveAuth(File_ID)\n",
        "file_name.GetContentFile('training.1600000.processed.noemoticon.csv')\n",
        "train_data = pd.read_csv('training.1600000.processed.noemoticon.csv',encoding='latin-1',header=None)\n",
        "train_data = pd.DataFrame(train_data)\n",
        "\n",
        "File_ID = '1VHDAjvUvaxwI-VoGbOdGX5RHqxsadQTP'\n",
        "file_name = GoogleDriveAuth(File_ID)\n",
        "file_name.GetContentFile('testdata.manual.2009.06.14.csv')\n",
        "test_data = pd.read_csv('testdata.manual.2009.06.14.csv',header=None)\n",
        "test_data = pd.DataFrame(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.11.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX3Ks-CWlPih",
        "colab_type": "code",
        "outputId": "958598c7-a6f1-4798-b060-c8407768b97d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "train_data=shuffle(train_data[[0,5]]).reset_index(drop=True)\n",
        "test_data=shuffle(test_data[[0,5]]).reset_index(drop=True)\n",
        "print(train_data.head())\n",
        "print(test_data.head())\n",
        "print(train_data[0].value_counts())\n",
        "print(test_data[0].value_counts())\n",
        "\n",
        "test_data=test_data.loc[test_data[0]!=2]\n",
        "print(test_data[0].value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0                                                  5\n",
            "0  0                             tired  goodnight    L \n",
            "1  0   well you didn t ask me if i wanted to move wi...\n",
            "2  0  is very sad    get well soon my beloved Cik Bi...\n",
            "3  4                                happy mother s day \n",
            "4  4     watching Canadian Nationals then JMO s Prom   \n",
            "   0                                                  5\n",
            "0  2  all about Ajax,jquery ,css ,JavaScript and mor...\n",
            "1  2           Going to see star trek soon with my dad.\n",
            "2  2  How to implement a news ticker with jQuery and...\n",
            "3  0  Give a man a fish, u feed him for the day. Tea...\n",
            "4  4  @sklososky Thanks so much!!! ...from one of yo...\n",
            "0    510\n",
            "4    490\n",
            "Name: 0, dtype: int64\n",
            "4    182\n",
            "0    177\n",
            "2    139\n",
            "Name: 0, dtype: int64\n",
            "4    182\n",
            "0    177\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bns0Q07VfYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_examples=10000\n",
        "train_data[0].value_counts()\n",
        "train_data=train_data[:training_examples]\n",
        "train_data[0].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhHFXE15xkPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clean\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "for i in range(training_examples):\n",
        "  train_data[5][i] = BeautifulSoup(train_data[5][i], 'lxml').get_text()   #HTML decoding\n",
        "  train_data[5][i]=re.sub(r'@[A-Za-z0-9]+','',train_data[5][i])           #@______\n",
        "  train_data[5][i]=re.sub('https?://[A-Za-z0-9./]+','',train_data[5][i])  #url\n",
        "  train_data[5][i]=re.sub(\"[^a-zA-Z]\", \" \", train_data[5][i])\n",
        "  train_data[5][i]=train_data[5][i].encode('utf-8').decode('utf-8').replace(u\"\\ufffd\", \"?\") #Byte-Order-Mark\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO3GXbZM97f-",
        "colab_type": "code",
        "outputId": "47b95614-c5ba-45b7-b1a4-7a530c68defb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1197
        }
      },
      "source": [
        "print(train_data.shape)\n",
        "train_data=train_data[:1000]\n",
        "train_data[5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Photo  maichau  b  a      p       p nh       T...\n",
              "1       OOOOH excellent  I WILL be listening and figh...\n",
              "2       yeah i loved the books  i couldnt even finish...\n",
              "3      Placed  th in funrun today in the       age gr...\n",
              "4      it s nice what sony has shown  but no price dr...\n",
              "5       I have sent you instructions for loading pics...\n",
              "6       No worries  Sharing the good news about our m...\n",
              "7       family is crazyyyy   lol grr ima go and wait ...\n",
              "8      i found all my gameboy games   disappointed i ...\n",
              "9       But SSIS is like an old friend and I hate reg...\n",
              "10     ARGH      what the hell is going on with the d...\n",
              "11     I have more gallbladder induced vomiting befor...\n",
              "12                                          thank you  x\n",
              "13     ALLi ThAt GiRL has free TACO BELL for   people...\n",
              "14                                  Thank you  my dear  \n",
              "15      lol  Man  I woke up thinkin about all kinds o...\n",
              "16     I m definitely excited to go back home to Gran...\n",
              "17     Feels like a act scratched the back of my thro...\n",
              "18                        Missing a whole lot of people \n",
              "19     The REAL google killer drives a street view ca...\n",
              "20       im just mad that my roomate is gay and i pay...\n",
              "21           BYE LC           commeeee on peeennnnsssss \n",
              "22     why oh why does there have to be zombie mutant...\n",
              "23                         Wishing I could be WITH YOU  \n",
              "24                      Hey buddy  Happy Sunday to you  \n",
              "25     season is over  St Johnstone take a     lead  ...\n",
              "26      As ossum as all the other ones  I want one  d...\n",
              "27     Installing JDK   update       But I can t use ...\n",
              "28     Got surprise B day blast from my friends   Thx...\n",
              "29                                 Yes  I need you all  \n",
              "                             ...                        \n",
              "970    Really wanted the hibatchi grill way to be a l...\n",
              "971        the porch at waihi beach is great for dinner \n",
              "972     Gr  newsletter   Will be making my priority l...\n",
              "973      extremely lucky it was very hot   you were r...\n",
              "974    taken was very       violenttt   not my kinda ...\n",
              "975                                  Good morning there \n",
              "976     i ve been to the park in my lunch break  but ...\n",
              "977     That s how it goes   it sucks   hate being br...\n",
              "978    OMG all these old faces are popping up out of ...\n",
              "979     except that denny s sucks   they re not as aw...\n",
              "980            wait for me in chat for a minute ill brb \n",
              "981                   omg i tink he is not cuming bckkk \n",
              "982     Start shooting next week  We need an on set s...\n",
              "983                   too bad we are on a hiring freeze \n",
              "984       hello matthew  welcome to my  little  twitter \n",
              "985     is an Internet Marketer  Promotional Consulta...\n",
              "986     Are you twating from the wedding  as in it is...\n",
              "987                                    I think we have  \n",
              "988     It drives me mad because I feel like such a n...\n",
              "989    I can t stop thinking about           wonder w...\n",
              "990     I m sorry baby  can t believe it s so expensi...\n",
              "991    good amount of sleep  check  shower  check  wo...\n",
              "992     lmao   how u doin besides looking for a partn...\n",
              "993                             nauw Miley your so cute \n",
              "994     well you didn t ask me if i wanted to move wi...\n",
              "995    kids in bed  max wouldn t go to bed unless i l...\n",
              "996       I m heeerrreee  bighugs   Why cant you spleep \n",
              "997    just found out that the last Titanic survivor ...\n",
              "998    itss soooo cramped in the den  my dad put this...\n",
              "999     Nah    LOL  What was that   I have to admit  ...\n",
              "Name: 5, Length: 1000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRcI7re5SS9W",
        "colab_type": "code",
        "outputId": "38d208b0-39b2-4465-d0e0-b6d767395de9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "import scipy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_data[5]).toarray()    # 01 2*2 matrix\n",
        "X_train = pd.DataFrame.from_records(X_train, columns=vectorizer.get_feature_names())\n",
        "\n",
        "#print(ktest)\n",
        "X_test=vectorizer.fit_transform(test_data[5][:10]).toarray() \n",
        "X_test = pd.DataFrame.from_records(X_test, columns=vectorizer.get_feature_names())    #makes column of different words\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "#print(X.shape)\n",
        "# print(X_test.shape)\n",
        "# print(Y_train.shape)\n",
        "# print(Y_test.shape)\n",
        "X_train\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 107)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 3127)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRuZicpy8QhS",
        "colab_type": "code",
        "outputId": "c15d7e67-1c69-4052-cc03-575470974dab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, train_data[0])\n",
        "\n",
        "\n",
        "X_test=X_test.append(X_train)    #merge two lists\n",
        "X_test=X_test[X_train.columns]  #keep only X_train columns\n",
        "\n",
        "where_are_NaNs = np.isnan(X_test)    #find new columns\n",
        "X_test[where_are_NaNs] = 0    #fill Nan with 0 an not present\n",
        "\n",
        "print('Predicted')\n",
        "print(clf.predict(X_test[0:100]))\n",
        "print('Actual')\n",
        "print(((test_data[0][:100]).as_matrix()))\n",
        "print('Accuracy=',clf.score(X_test[0:100], test_data[0][:100]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted\n",
            "[4 4 0 4 4 4 4 0 4 4 0 0 0 4 4 0 0 4 4 0 0 4 4 0 4 0 4 4 4 0 4 0 4 0 4 0 4\n",
            " 0 4 4 0 4 0 4 4 4 0 0 0 0 0 4 4 0 4 0 4 0 4 0 4 4 0 4 4 4 0 4 4 0 0 0 0 4\n",
            " 0 4 4 4 4 0 4 0 4 0 4 0 4 0 0 0 4 0 4 0 0 4 0 4 4 4]\n",
            "Actual\n",
            "[0 4 0 0 0 0 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 4 0 4 4 4 0 0 4 0 4 4 4 0 4 4 4\n",
            " 0 0 0 4 4 4 4 4 4 4 4 0 0 4 4 4 0 0 0 0 0 0 4 4 4 0 0 4 0 4 0 4 0 0 0 0 0\n",
            " 0 0 4 0 0 4 4 4 4 0 0 0 0 4 0 0 4 4 0 4 0 4 4 4 4 4]\n",
            "Accuracy= 0.55\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}